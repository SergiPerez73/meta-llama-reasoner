{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta llama rational steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLlamaRationalSteps:\n",
    "\n",
    "    def __init__(self, max_tokens=1200):\n",
    "        CONFIG = dotenv_values(\"config/.env\")\n",
    "\n",
    "        self.client = Groq(api_key=CONFIG[\"GROQ_API_KEY\"])\n",
    "        self.model_name = CONFIG[\"MODEL_NAME\"]\n",
    "        self.max_tokens = max_tokens\n",
    "    \n",
    "    def question_steps_answer(self, question, system_prompt=\"Answer the following question\"):\n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"{system_prompt}\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{question}\"\n",
    "                }\n",
    "            ],\n",
    "            model=self.model_name,\n",
    "            max_tokens=self.max_tokens\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            rational_step = answer.split(\"</think>\")[0].replace(\"<think>\", \"\")\n",
    "            final_answer = answer.split(\"</think>\")[1].replace(\"<answer>\", \"\").replace(\"</answer>\", \"\").replace(\"\\n\", \"\")\n",
    "        except:\n",
    "            rational_step = \"format error\"\n",
    "            final_answer = \"format error\"\n",
    "\n",
    "        return rational_step, final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rational_steps = MetaLlamaRationalSteps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Find a word that relates the word 'novel' and the word 'hotel'\"\n",
    "rational_step = model_rational_steps.question_steps_answer(question=question, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRewardPrediction(nn.Module):\n",
    "    def __init__(self, layer_config_embedding, layer_config_general, n_embeddings=2):\n",
    "        super(ModelRewardPrediction, self).__init__()\n",
    "        \n",
    "        # Create embedding layers\n",
    "        self.embedding_layers = nn.ModuleList()\n",
    "        for _ in range(n_embeddings):\n",
    "            layers = []\n",
    "            input_dim = 768\n",
    "            layer_dims = [int(dim) for dim in layer_config_embedding.split()]\n",
    "            \n",
    "            for dim in layer_dims:\n",
    "                layers.append(nn.Linear(input_dim, dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                input_dim = dim\n",
    "            \n",
    "            layers.pop()  # Remove the last ReLU\n",
    "            self.embedding_layers.append(nn.Sequential(*layers))\n",
    "        \n",
    "        # Create general layers\n",
    "        layers = []\n",
    "        input_dim = n_embeddings * layer_dims[-1]\n",
    "        layer_dims = [int(dim) for dim in layer_config_general.split()]\n",
    "        \n",
    "        for dim in layer_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        \n",
    "        layers.pop()  # Remove the last ReLU\n",
    "        layers.append(nn.Sigmoid())  # Add Sigmoid for the final layer\n",
    "        \n",
    "        self.general_layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        # Apply embedding layers to each input\n",
    "        x_output_list = []\n",
    "        for i, x in enumerate(x_list):\n",
    "            x_output_list.append(self.embedding_layers[i](x))\n",
    "        \n",
    "        # Concatenate the outputs\n",
    "        x = torch.cat(x_output_list, dim=1)\n",
    "        \n",
    "        # Apply general layers\n",
    "        return self.general_layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4909],\n",
      "        [0.4907]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_config_embedding = \"512 256\"\n",
    "layer_config_general = \"256 128 1\"\n",
    "model = ModelRewardPrediction(layer_config_embedding, layer_config_general)\n",
    "x1 = torch.randn(2, 768)\n",
    "x2 = torch.randn(2, 768)\n",
    "output = model([x1, x2])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embeddings = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "def get_embedding(sentence):\n",
    "    embedding = model_embeddings.encode(sentence)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIME_Dataset = pd.read_csv(\"data/AIME_Dataset_1983_2024.csv\")\n",
    "AIME_Dataset = AIME_Dataset[['Question', 'Answer']]\n",
    "AIME_Dataset_clarification_prompt = \" The Answer must only contain a nummber, not an explanation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_config_embedding = \"512 256\"\n",
    "layer_config_general = \"256 128 1\"\n",
    "model_reward_accuracy = ModelRewardPrediction(layer_config_embedding, layer_config_general, n_embeddings=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_reward_accuracy.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = {\n",
    "    'Question_number': [],\n",
    "    'Question': [],\n",
    "    'Score': [],\n",
    "    'Loss': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    question = AIME_Dataset.iloc[i]['Question']\n",
    "    answer = AIME_Dataset.iloc[i]['Answer']\n",
    "\n",
    "    question_embedding_list = []\n",
    "    rational_step_embedding_list = []\n",
    "    score_list = []\n",
    "    for j in range(3):\n",
    "        rational_step, model_answer = model_rational_steps.question_steps_answer(question=question, system_prompt=system_prompt+AIME_Dataset_clarification_prompt)\n",
    "        model_answer = model_answer.replace(\" \", \"\")\n",
    "\n",
    "        score = 0\n",
    "        if model_answer == answer:\n",
    "            score = 1\n",
    "        \n",
    "        score = torch.tensor(score).float().view(1, 1)\n",
    "        question_embedding = torch.tensor(get_embedding(question)).unsqueeze(0)\n",
    "        rational_step_embedding = torch.tensor(get_embedding(rational_step)).unsqueeze(0)\n",
    "\n",
    "        score_list.append(score)\n",
    "        question_embedding_list.append(question_embedding)\n",
    "        rational_step_embedding_list.append(rational_step_embedding)    \n",
    "    \n",
    "    score = torch.cat(score_list, dim=0)\n",
    "    question_embedding = torch.cat(question_embedding_list, dim=0)\n",
    "    rational_step_embedding = torch.cat(rational_step_embedding_list, dim=0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_reward_accuracy([question_embedding, rational_step_embedding])\n",
    "    loss = criterion(outputs, score)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    training_dict['Question_number'].append(i)\n",
    "    training_dict['Question'].append(question)\n",
    "    training_dict['Score'].append(score.mean().item())\n",
    "    training_dict['Loss'].append(loss.item())\n",
    "\n",
    "    time.sleep(60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(training_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_number</th>\n",
       "      <th>Question</th>\n",
       "      <th>Score</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Let $x$ , $y$ and $z$ all exceed $1$ and let $...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Let $f(x)=|x-p|+|x-15|+|x-p-15|$ , where $0 &lt; ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the product of the real roots of the e...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A machine-shop cutting tool has the shape of a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_number                                           Question  \\\n",
       "0                0  Let $x$ , $y$ and $z$ all exceed $1$ and let $...   \n",
       "1                1  Let $f(x)=|x-p|+|x-15|+|x-p-15|$ , where $0 < ...   \n",
       "2                2  What is the product of the real roots of the e...   \n",
       "3                3  A machine-shop cutting tool has the shape of a...   \n",
       "\n",
       "      Score      Loss  \n",
       "0  0.666667  0.682087  \n",
       "1  0.666667  0.682019  \n",
       "2  0.000000  0.728643  \n",
       "3  1.000000  0.659012  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738352235"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtain a df with the results on every step\n",
    "* Pass all to actual code\n",
    "* Comment code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groq2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
